{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12ef40fc-7112-4da3-bea3-1635f4d9d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_community.document_loaders.readthedocs import ReadTheDocsLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"OPENAI_API_KEY_PERSONAL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903241c8-aade-4e25-839d-31f454e82fb1",
   "metadata": {},
   "source": [
    "## Ingestion Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e8077c3-1635-4950-a000-5a395435bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_docs(filePath, index_name, embedding_model):\n",
    "    \n",
    "    loader = ReadTheDocsLoader(filePath)\n",
    "    text = loader.load()\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size = 600, chunk_overlap = 50)\n",
    "    documents = splitter.split_documents(text)\n",
    "    embeddings = OpenAIEmbeddings(model = embedding_model)\n",
    "    vector_store = PineconeVectorStore(index_name = index_name, embedding=embeddings)\n",
    "    \n",
    "    batch_size, ingestion_id_all = 256, []\n",
    "    for index in range(0, len(documents), batch_size):\n",
    "        try:\n",
    "            batch_insert_entitiy = documents[index: index + batch_size]\n",
    "        except Exception as e:\n",
    "            batch_insert_entitiy = documents[index:]\n",
    "    \n",
    "        ingestion_ids = vector_store.add_documents(batch_insert_entitiy)\n",
    "        ingestion_id_all.extend(ingestion_ids)\n",
    "        print(\".\", end=\"\")\n",
    "\n",
    "file_path = \"../data/langchain-docs/api.python.langchain.com/en/latest/\"\n",
    "ingest_docs(filePath = file_path, index_name = \"langchain-chabot\", embedding_model = \"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11892599-1c4e-4b23-9ad9-0fe64222e117",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04f4730b-960a-4dd8-9477-226938918101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents.stuff import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ddc9c25a-a35f-4200-b9bf-bf0109893b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rag_agent(model, index_name, embeddings):\n",
    "    retrieval_qa = hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
    "    llm = ChatOpenAI(model = model)\n",
    "    embeddings = OpenAIEmbeddings(model = embeddings)\n",
    "    vector_store = PineconeVectorStore(index_name = index_name, embedding=embeddings)\n",
    "    combine_docs_chain = create_stuff_documents_chain(llm = llm, prompt = retrieval_qa)\n",
    "    retrieval_qa_agent = create_retrieval_chain(retriever = vector_store.as_retriever(), \n",
    "                                                combine_docs_chain = combine_docs_chain)\n",
    "    return retrieval_qa_agent\n",
    "\n",
    "retrieval_qa_agent = get_rag_agent(model = \"gpt-4o-mini\", index_name = \"langchain-chabot\", embeddings = \"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2ec0052a-e91d-4085-9915-9de9dd6d5cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_result = retrieval_qa_agent.invoke({\"input\": \"How to use OllamaEmbeddings in Langchain\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "86666278-e354-4930-b674-50a39bc840fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use `OllamaEmbeddings` in Langchain, you can follow these general steps:\n",
      "\n",
      "1. **Import the necessary module**: Ensure you have imported the `OllamaEmbeddings` from the embeddings package.\n",
      "\n",
      "   ```python\n",
      "   from embeddings.ollama import OllamaEmbeddings\n",
      "   ```\n",
      "\n",
      "2. **Instantiate the `OllamaEmbeddings` model**: Create an instance of the `OllamaEmbeddings` class. You'll need to configure any required parameters if necessary.\n",
      "\n",
      "   ```python\n",
      "   ollama_embeddings = OllamaEmbeddings()\n",
      "   ```\n",
      "\n",
      "3. **Prepare your data**: You need to have strings or `_Embed` objects that you want to embed.\n",
      "\n",
      "4. **Embed your data**: Use the instance you created to embed your strings or objects.\n",
      "\n",
      "   ```python\n",
      "   embeddings = ollama_embeddings.embed([\"Your text string here\"])\n",
      "   ```\n",
      "\n",
      "5. **Utilize the embeddings**: Once you have your embeddings, you can use them in your Langchain pipeline or for any further processing or analysis.\n",
      "\n",
      "This is a high-level overview, and the exact implementation might vary based on your specific requirements and the context of your use case.\n"
     ]
    }
   ],
   "source": [
    "print(sample_result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a1d504-3a15-4203-840f-966e6b0ccee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8d5a35f-1d2b-4588-8a8e-59dd2b4fe428",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingestion_ids.extend([\"A\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2966e267-4d81-415f-8498-f9afb170c5fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cb53a5ab-d051-49e9-95e9-6f73bfe6eaaf',\n",
       " '3f618d82-f889-4b01-acd3-e667a8254089',\n",
       " '5e5bfca4-8984-4a2f-b833-4f205f355c44',\n",
       " 'e0ed979f-7c81-4f2c-85ef-34f884f03627',\n",
       " '27398b8c-2f18-4e21-b2fa-5e07f6096418',\n",
       " '7ff53580-72cf-493d-90c5-6000b2557be4',\n",
       " '4636c174-e7b0-442c-a0f2-3daf2195d45c',\n",
       " 'ca05f607-d66a-499e-8c84-4815bf544467',\n",
       " 'fcfe550a-cef2-4320-b4ab-602de68d994e',\n",
       " 'c53df134-8023-412b-b60c-bc126866f0ea',\n",
       " '918689be-2620-4ab5-90bf-cbf9028a88f8',\n",
       " '07e9806f-e8fc-4f1c-a596-a8dc980e8493',\n",
       " 'c0c4e569-9441-400a-875f-98c2a4461634',\n",
       " '0eb61616-3be0-41e2-b53a-604f205f172f',\n",
       " '76de2a4b-cb1c-464e-9130-100ea69369b0',\n",
       " 'c970793a-c081-4b65-9ce5-3a767c8205d8',\n",
       " 'bd2b8fcc-03d6-4b8b-97bf-0e45d94127f9',\n",
       " 'b4ed5ca2-b7b1-4ebf-a02c-12057549c5aa',\n",
       " '4a3a09de-9d05-4f33-9e4a-b3f455b7174d',\n",
       " '25249280-6e31-47d1-a91b-4a7108b4e943',\n",
       " 'e54ebfb0-4462-4fc0-a071-4082ba964d72',\n",
       " '695f28ed-2bed-4a26-9fb7-93e03aee5a50',\n",
       " '57f87d5b-b556-4e33-8dc5-5e1bf5a7406f',\n",
       " 'A']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingestion_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f53cb47-f756-44a2-a996-31880eec5d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "108069e9-d872-4fa5-ac75-8b0e49b59177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba8a9fa3-5783-4d89-b5d5-42ba199c5aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '../data/langchain-docs/api.python.langchain.com/en/latest/experimental_api_reference.html'}, page_content='Load the ResponseGenerator.\\nautonomous_agents.hugginggpt.task_planner.load_chat_planner(llm)\\nLoad the chat planner.\\nlangchain_experimental.chat_models¶\\nChat Models are a variation on language models.\\nWhile Chat Models use language models under the hood, the interface they expose\\nis a bit different. Rather than expose a “text in, text out” API, they expose\\nan interface where “chat messages” are the inputs and outputs.\\nClass hierarchy:\\nBaseLanguageModel --> BaseChatModel --> <name>  # Examples: ChatOpenAI, ChatGooglePalm\\nMain helpers:\\nAIMessage, BaseMessage, HumanMessage\\nClasses¶\\nchat_models.llm_wrapper.ChatWrapper\\nWrapper for chat LLMs.\\nchat_models.llm_wrapper.Llama2Chat\\nWrapper for Llama-2-chat model.\\nchat_models.llm_wrapper.Mixtral\\nSee https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1#instruction-format\\nchat_models.llm_wrapper.Orca\\nWrapper for Orca-style models.\\nchat_models.llm_wrapper.Vicuna\\nWrapper for Vicuna-style models.\\nlangchain_experimental.comprehend_moderation¶\\nComprehend Moderation is used to detect and handle Personally Identifiable Information (PII),\\ntoxicity, and prompt safety in text.\\nThe Langchain experimental package includes the AmazonComprehendModerationChain class\\nfor the comprehend moderation tasks. It is based on Amazon Comprehend service.\\nThis class can be configured with specific moderation settings like PII labels, redaction,\\ntoxicity thresholds, and prompt safety thresholds.\\nSee more at https://aws.amazon.com/comprehend/\\nAmazon Comprehend service is used by several other classes:\\n- ComprehendToxicity class is used to check the toxicity of text prompts using\\nAWS Comprehend service and take actions based on the configuration\\nComprehendPromptSafety class is used to validate the safety of given prompt\\ntext, raising an error if unsafe content is detected based on the specified threshold\\nComprehendPII class is designed to handle\\nPersonally Identifiable Information (PII) moderation tasks,\\ndetecting and managing PII entities in text inputs\\nClasses¶\\ncomprehend_moderation.amazon_comprehend_moderation.AmazonComprehendModerationChain\\nModeration Chain, based on Amazon Comprehend service.\\ncomprehend_moderation.base_moderation.BaseModeration(client)\\nBase class for moderation.\\ncomprehend_moderation.base_moderation_callbacks.BaseModerationCallbackHandler()\\nBase class for moderation callback handlers.\\ncomprehend_moderation.base_moderation_config.BaseModerationConfig\\nBase configuration settings for moderation.\\ncomprehend_moderation.base_moderation_config.ModerationPiiConfig\\nConfiguration for PII moderation filter.\\ncomprehend_moderation.base_moderation_config.ModerationPromptSafetyConfig\\nConfiguration for Prompt Safety moderation filter.\\ncomprehend_moderation.base_moderation_config.ModerationToxicityConfig\\nConfiguration for Toxicity moderation filter.\\ncomprehend_moderation.base_moderation_exceptions.ModerationPiiError([...])\\nException raised if PII entities are detected.\\ncomprehend_moderation.base_moderation_exceptions.ModerationPromptSafetyError([...])\\nException raised if Unsafe prompts are detected.\\ncomprehend_moderation.base_moderation_exceptions.ModerationToxicityError([...])\\nException raised if Toxic entities are detected.\\ncomprehend_moderation.pii.ComprehendPII(client)\\nClass to handle Personally Identifiable Information (PII) moderation.\\ncomprehend_moderation.prompt_safety.ComprehendPromptSafety(client)\\nClass to handle prompt safety moderation.\\ncomprehend_moderation.toxicity.ComprehendToxicity(client)\\nClass to handle toxicity moderation.\\nlangchain_experimental.cpal¶\\nCausal program-aided language (CPAL) is a concept implemented in LangChain as\\na chain for causal modeling and narrative decomposition.\\nCPAL improves upon the program-aided language (PAL) by incorporating\\ncausal structure to prevent hallucination in language models,\\nparticularly when dealing with complex narratives and math\\nproblems with nested dependencies.\\nCPAL involves translating causal narratives into a stack of operations,')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66b78839-5a50-4ed4-b2dd-5090947b1a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '../data/langchain-docs/api.python.langchain.com/en/latest/experimental_api_reference.html'}, page_content='langchain_experimental 0.0.62¶\\nlangchain_experimental.agents¶\\nAgent is a class that uses an LLM to choose\\na sequence of actions to take.\\nIn Chains, a sequence of actions is hardcoded. In Agents,\\na language model is used as a reasoning engine to determine which actions\\nto take and in which order.\\nAgents select and use Tools and Toolkits for actions.\\nFunctions¶\\nagents.agent_toolkits.csv.base.create_csv_agent(...)\\nCreate pandas dataframe agent by loading csv to a dataframe.\\nagents.agent_toolkits.pandas.base.create_pandas_dataframe_agent(llm,\\xa0df)\\nConstruct a Pandas agent from an LLM and dataframe(s).\\nagents.agent_toolkits.python.base.create_python_agent(...)\\nConstruct a python agent from an LLM and tool.\\nagents.agent_toolkits.spark.base.create_spark_dataframe_agent(llm,\\xa0df)\\nConstruct a Spark agent from an LLM and dataframe.\\nagents.agent_toolkits.xorbits.base.create_xorbits_agent(...)\\nConstruct a xorbits agent from an LLM and dataframe.\\nlangchain_experimental.autonomous_agents¶\\nAutonomous agents in the Langchain experimental package include\\n[AutoGPT](https://github.com/Significant-Gravitas/AutoGPT),\\n[BabyAGI](https://github.com/yoheinakajima/babyagi),\\nand [HuggingGPT](https://arxiv.org/abs/2303.17580) agents that\\ninteract with language models autonomously.\\nThese agents have specific functionalities like memory management,\\ntask creation, execution chains, and response generation.\\nThey differ from ordinary agents by their autonomous decision-making capabilities,\\nmemory handling, and specialized functionalities for tasks and response.\\nClasses¶\\nautonomous_agents.autogpt.agent.AutoGPT(...)\\nAgent for interacting with AutoGPT.\\nautonomous_agents.autogpt.memory.AutoGPTMemory\\nMemory for AutoGPT.\\nautonomous_agents.autogpt.output_parser.AutoGPTAction(...)\\nAction returned by AutoGPTOutputParser.\\nautonomous_agents.autogpt.output_parser.AutoGPTOutputParser\\nOutput parser for AutoGPT.\\nautonomous_agents.autogpt.output_parser.BaseAutoGPTOutputParser\\nBase Output parser for AutoGPT.\\nautonomous_agents.autogpt.prompt.AutoGPTPrompt\\nPrompt for AutoGPT.\\nautonomous_agents.autogpt.prompt_generator.PromptGenerator()\\nGenerator of custom prompt strings.\\nautonomous_agents.baby_agi.baby_agi.BabyAGI\\nController model for the BabyAGI agent.\\nautonomous_agents.baby_agi.task_creation.TaskCreationChain\\nChain generating tasks.\\nautonomous_agents.baby_agi.task_execution.TaskExecutionChain\\nChain to execute tasks.\\nautonomous_agents.baby_agi.task_prioritization.TaskPrioritizationChain\\nChain to prioritize tasks.\\nautonomous_agents.hugginggpt.hugginggpt.HuggingGPT(...)\\nAgent for interacting with HuggingGPT.\\nautonomous_agents.hugginggpt.repsonse_generator.ResponseGenerationChain\\nChain to execute tasks.\\nautonomous_agents.hugginggpt.repsonse_generator.ResponseGenerator(...)\\nGenerates a response based on the input.\\nautonomous_agents.hugginggpt.task_executor.Task(...)\\nTask to be executed.\\nautonomous_agents.hugginggpt.task_executor.TaskExecutor(plan)\\nLoad tools and execute tasks.\\nautonomous_agents.hugginggpt.task_planner.BasePlanner\\nBase class for a planner.\\nautonomous_agents.hugginggpt.task_planner.Plan(steps)\\nA plan to execute.\\nautonomous_agents.hugginggpt.task_planner.PlanningOutputParser\\nParses the output of the planning stage.\\nautonomous_agents.hugginggpt.task_planner.Step(...)\\nA step in the plan.\\nautonomous_agents.hugginggpt.task_planner.TaskPlaningChain\\nChain to execute tasks.\\nautonomous_agents.hugginggpt.task_planner.TaskPlanner\\nPlanner for tasks.\\nFunctions¶\\nautonomous_agents.autogpt.output_parser.preprocess_json_input(...)\\nPreprocesses a string to be parsed as json.\\nautonomous_agents.autogpt.prompt_generator.get_prompt(tools)\\nGenerates a prompt string.\\nautonomous_agents.hugginggpt.repsonse_generator.load_response_generator(llm)\\nLoad the ResponseGenerator.\\nautonomous_agents.hugginggpt.task_planner.load_chat_planner(llm)\\nLoad the chat planner.\\nlangchain_experimental.chat_models¶\\nChat Models are a variation on language models.\\nWhile Chat Models use language models under the hood, the interface they expose\\nis a bit different. Rather than expose a “text in, text out” API, they expose\\nan interface where “chat messages” are the inputs and outputs.\\nClass hierarchy:\\nBaseLanguageModel --> BaseChatModel --> <name>  # Examples: ChatOpenAI, ChatGooglePalm\\nMain helpers:\\nAIMessage, BaseMessage, HumanMessage\\nClasses¶\\nchat_models.llm_wrapper.ChatWrapper\\nWrapper for chat LLMs.\\nchat_models.llm_wrapper.Llama2Chat\\nWrapper for Llama-2-chat model.\\nchat_models.llm_wrapper.Mixtral\\nSee https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1#instruction-format\\nchat_models.llm_wrapper.Orca\\nWrapper for Orca-style models.\\nchat_models.llm_wrapper.Vicuna\\nWrapper for Vicuna-style models.\\nlangchain_experimental.comprehend_moderation¶\\nComprehend Moderation is used to detect and handle Personally Identifiable Information (PII),\\ntoxicity, and prompt safety in text.\\nThe Langchain experimental package includes the AmazonComprehendModerationChain class\\nfor the comprehend moderation tasks. It is based on Amazon Comprehend service.\\nThis class can be configured with specific moderation settings like PII labels, redaction,\\ntoxicity thresholds, and prompt safety thresholds.\\nSee more at https://aws.amazon.com/comprehend/\\nAmazon Comprehend service is used by several other classes:\\n- ComprehendToxicity class is used to check the toxicity of text prompts using\\nAWS Comprehend service and take actions based on the configuration\\nComprehendPromptSafety class is used to validate the safety of given prompt\\ntext, raising an error if unsafe content is detected based on the specified threshold\\nComprehendPII class is designed to handle\\nPersonally Identifiable Information (PII) moderation tasks,\\ndetecting and managing PII entities in text inputs\\nClasses¶\\ncomprehend_moderation.amazon_comprehend_moderation.AmazonComprehendModerationChain\\nModeration Chain, based on Amazon Comprehend service.\\ncomprehend_moderation.base_moderation.BaseModeration(client)\\nBase class for moderation.\\ncomprehend_moderation.base_moderation_callbacks.BaseModerationCallbackHandler()\\nBase class for moderation callback handlers.\\ncomprehend_moderation.base_moderation_config.BaseModerationConfig\\nBase configuration settings for moderation.\\ncomprehend_moderation.base_moderation_config.ModerationPiiConfig\\nConfiguration for PII moderation filter.\\ncomprehend_moderation.base_moderation_config.ModerationPromptSafetyConfig\\nConfiguration for Prompt Safety moderation filter.\\ncomprehend_moderation.base_moderation_config.ModerationToxicityConfig\\nConfiguration for Toxicity moderation filter.\\ncomprehend_moderation.base_moderation_exceptions.ModerationPiiError([...])\\nException raised if PII entities are detected.\\ncomprehend_moderation.base_moderation_exceptions.ModerationPromptSafetyError([...])\\nException raised if Unsafe prompts are detected.\\ncomprehend_moderation.base_moderation_exceptions.ModerationToxicityError([...])\\nException raised if Toxic entities are detected.\\ncomprehend_moderation.pii.ComprehendPII(client)\\nClass to handle Personally Identifiable Information (PII) moderation.\\ncomprehend_moderation.prompt_safety.ComprehendPromptSafety(client)\\nClass to handle prompt safety moderation.\\ncomprehend_moderation.toxicity.ComprehendToxicity(client)\\nClass to handle toxicity moderation.\\nlangchain_experimental.cpal¶\\nCausal program-aided language (CPAL) is a concept implemented in LangChain as\\na chain for causal modeling and narrative decomposition.\\nCPAL improves upon the program-aided language (PAL) by incorporating\\ncausal structure to prevent hallucination in language models,\\nparticularly when dealing with complex narratives and math\\nproblems with nested dependencies.\\nCPAL involves translating causal narratives into a stack of operations,\\nsetting hypothetical conditions for causal models, and decomposing\\nnarratives into story elements.\\nIt allows for the creation of causal chains that define the relationships\\nbetween different elements in a narrative, enabling the modeling and analysis\\nof causal relationships within a given context.\\nClasses¶\\ncpal.base.CPALChain\\nCausal program-aided language (CPAL) chain implementation.\\ncpal.base.CausalChain\\nTranslate the causal narrative into a stack of operations.\\ncpal.base.InterventionChain\\nSet the hypothetical conditions for the causal model.\\ncpal.base.NarrativeChain\\nDecompose the narrative into its story elements.\\ncpal.base.QueryChain\\nQuery the outcome table using SQL.\\ncpal.constants.Constant(value)\\nEnum for constants used in the CPAL.\\ncpal.models.CausalModel\\nCasual data.\\ncpal.models.EntityModel\\nEntity in the story.\\ncpal.models.EntitySettingModel\\nEntity initial conditions.\\ncpal.models.InterventionModel\\nIntervention data of the story aka initial conditions.\\ncpal.models.NarrativeModel\\nNarrative input as three story elements.\\ncpal.models.QueryModel\\nQuery data of the story.\\ncpal.models.ResultModel\\nResult of the story query.\\ncpal.models.StoryModel\\nStory data.\\ncpal.models.SystemSettingModel\\nSystem initial conditions.\\nlangchain_experimental.data_anonymizer¶\\nData anonymizer contains both Anonymizers and Deanonymizers.\\nIt uses the [Microsoft Presidio](https://microsoft.github.io/presidio/) library.\\nAnonymizers are used to replace a Personally Identifiable Information (PII)\\nentity text with some other\\nvalue by applying a certain operator (e.g. replace, mask, redact, encrypt).\\nDeanonymizers are used to revert the anonymization operation\\n(e.g. to decrypt an encrypted text).\\nClasses¶\\ndata_anonymizer.base.AnonymizerBase()\\nBase abstract class for anonymizers.\\ndata_anonymizer.base.ReversibleAnonymizerBase()\\nBase abstract class for reversible anonymizers.\\ndata_anonymizer.deanonymizer_mapping.DeanonymizerMapping(...)\\nDeanonymizer mapping.\\ndata_anonymizer.presidio.PresidioAnonymizer([...])\\nAnonymizer using Microsoft Presidio.\\ndata_anonymizer.presidio.PresidioAnonymizerBase([...])\\nBase Anonymizer using Microsoft Presidio.\\ndata_anonymizer.presidio.PresidioReversibleAnonymizer([...])\\nReversible Anonymizer using Microsoft Presidio.\\nFunctions¶\\ndata_anonymizer.deanonymizer_mapping.create_anonymizer_mapping(...)\\nCreate or update the mapping used to anonymize and/or\\ndata_anonymizer.deanonymizer_mapping.format_duplicated_operator(...)\\nFormat the operator name with the count.\\ndata_anonymizer.deanonymizer_matching_strategies.case_insensitive_matching_strategy(...)\\nCase insensitive matching strategy for deanonymization.\\ndata_anonymizer.deanonymizer_matching_strategies.combined_exact_fuzzy_matching_strategy(...)\\nCombined exact and fuzzy matching strategy for deanonymization.\\ndata_anonymizer.deanonymizer_matching_strategies.exact_matching_strategy(...)\\nExact matching strategy for deanonymization.\\ndata_anonymizer.deanonymizer_matching_strategies.fuzzy_matching_strategy(...)\\nFuzzy matching strategy for deanonymization.\\ndata_anonymizer.deanonymizer_matching_strategies.ngram_fuzzy_matching_strategy(...)\\nN-gram fuzzy matching strategy for deanonymization.\\ndata_anonymizer.faker_presidio_mapping.get_pseudoanonymizer_mapping([seed])\\nGet a mapping of entities to pseudo anonymize them.\\nlangchain_experimental.fallacy_removal¶\\nFallacy Removal Chain runs a self-review of logical fallacies\\nas determined by paper\\n[Robust and Explainable Identification of Logical Fallacies in Natural\\nLanguage Arguments](https://arxiv.org/pdf/2212.07425.pdf).\\nIt is modeled after Constitutional AI and in the same format, but applying logical\\nfallacies as generalized rules to remove them in output.\\nClasses¶\\nfallacy_removal.base.FallacyChain\\nChain for applying logical fallacy evaluations.\\nfallacy_removal.models.LogicalFallacy\\nLogical fallacy.\\nlangchain_experimental.generative_agents¶\\nGenerative Agent primitives.\\nClasses¶\\ngenerative_agents.generative_agent.GenerativeAgent\\nAgent as a character with memory and innate characteristics.\\ngenerative_agents.memory.GenerativeAgentMemory\\nMemory for the generative agent.\\nlangchain_experimental.graph_transformers¶\\nGraph Transformers transform Documents into Graph Documents.\\nClasses¶\\ngraph_transformers.diffbot.DiffbotGraphTransformer(...)\\nTransform documents into graph documents using Diffbot NLP API.\\ngraph_transformers.diffbot.NodesList()\\nList of nodes with associated properties.\\ngraph_transformers.diffbot.SimplifiedSchema()\\nSimplified schema mapping.\\ngraph_transformers.diffbot.TypeOption(value)\\nAn enumeration.\\ngraph_transformers.llm.LLMGraphTransformer(llm)\\nTransform documents into graph-based documents using a LLM.\\ngraph_transformers.llm.UnstructuredRelation\\nCreate a new model by parsing and validating input data from keyword arguments.\\nFunctions¶\\ngraph_transformers.diffbot.format_property_key(s)\\nFormats a string to be used as a property key.\\ngraph_transformers.llm.create_simple_model([...])\\nCreate a simple graph model with optional constraints on node and relationship types.\\ngraph_transformers.llm.create_unstructured_prompt([...])\\ngraph_transformers.llm.format_property_key(s)\\ngraph_transformers.llm.map_to_base_node(node)\\nMap the SimpleNode to the base Node.\\ngraph_transformers.llm.map_to_base_relationship(rel)\\nMap the SimpleRelationship to the base Relationship.\\ngraph_transformers.llm.optional_enum_field([...])\\nUtility function to conditionally create a field with an enum constraint.\\nlangchain_experimental.llm_bash¶\\nLLM bash is a chain that uses LLM to interpret a prompt and\\nexecutes bash code.\\nClasses¶\\nllm_bash.base.LLMBashChain\\nChain that interprets a prompt and executes bash operations.\\nllm_bash.bash.BashProcess([strip_newlines,\\xa0...])\\nWrapper for starting subprocesses.\\nllm_bash.prompt.BashOutputParser\\nParser for bash output.\\nlangchain_experimental.llm_symbolic_math¶\\nChain that interprets a prompt and executes python code to do math.\\nHeavily borrowed from llm_math, uses the [SymPy](https://www.sympy.org/) package.\\nClasses¶\\nllm_symbolic_math.base.LLMSymbolicMathChain\\nChain that interprets a prompt and executes python code to do symbolic math.\\nlangchain_experimental.llms¶\\nExperimental LLM classes provide\\naccess to the large language model (LLM) APIs and services.\\nClasses¶\\nllms.anthropic_functions.AnthropicFunctions\\n[Deprecated] Chat model for interacting with Anthropic functions.\\nllms.anthropic_functions.TagParser()\\nParser for the tool tags.\\nllms.jsonformer_decoder.JsonFormer\\nJsonformer wrapped LLM using HuggingFace Pipeline API.\\nllms.llamaapi.ChatLlamaAPI\\nChat model using the Llama API.\\nllms.lmformatenforcer_decoder.LMFormatEnforcer\\nLMFormatEnforcer wrapped LLM using HuggingFace Pipeline API.\\nllms.ollama_functions.OllamaFunctions\\nFunction chat model that uses Ollama API.\\nllms.rellm_decoder.RELLM\\nRELLM wrapped LLM using HuggingFace Pipeline API.\\nFunctions¶\\nllms.jsonformer_decoder.import_jsonformer()\\nLazily import of the jsonformer package.\\nllms.lmformatenforcer_decoder.import_lmformatenforcer()\\nLazily import of the lmformatenforcer package.\\nllms.ollama_functions.convert_to_ollama_tool(tool)\\nConvert a tool to an Ollama tool.\\nllms.ollama_functions.parse_response(message)\\nExtract function_call from AIMessage.\\nllms.rellm_decoder.import_rellm()\\nLazily import of the rellm package.\\nlangchain_experimental.open_clip¶\\nOpenCLIP Embeddings model.\\nOpenCLIP is a multimodal model that can encode text and images into a shared space.\\nSee this paper for more details: https://arxiv.org/abs/2103.00020\\nand [this repository](https://github.com/mlfoundations/open_clip) for details.\\nClasses¶\\nopen_clip.open_clip.OpenCLIPEmbeddings\\nOpenCLIP Embeddings model.\\nlangchain_experimental.pal_chain¶\\nPAL Chain implements Program-Aided Language Models.\\nSee the paper: https://arxiv.org/pdf/2211.10435.pdf.\\nThis chain is vulnerable to [arbitrary code execution](https://github.com/langchain-ai/langchain/issues/5872).\\nClasses¶\\npal_chain.base.PALChain\\nChain that implements Program-Aided Language Models (PAL).\\npal_chain.base.PALValidation([...])\\nValidation for PAL generated code.\\nlangchain_experimental.plan_and_execute¶\\nPlan-and-execute agents are planning tasks with a language model (LLM) and\\nexecuting them with a separate agent.\\nClasses¶\\nplan_and_execute.agent_executor.PlanAndExecute\\nPlan and execute a chain of steps.\\nplan_and_execute.executors.base.BaseExecutor\\nBase executor.\\nplan_and_execute.executors.base.ChainExecutor\\nChain executor.\\nplan_and_execute.planners.base.BasePlanner\\nBase planner.\\nplan_and_execute.planners.base.LLMPlanner\\nLLM planner.\\nplan_and_execute.planners.chat_planner.PlanningOutputParser\\nPlanning output parser.\\nplan_and_execute.schema.BaseStepContainer\\nBase step container.\\nplan_and_execute.schema.ListStepContainer\\nContainer for List of steps.\\nplan_and_execute.schema.Plan\\nPlan.\\nplan_and_execute.schema.PlanOutputParser\\nPlan output parser.\\nplan_and_execute.schema.Step\\nStep.\\nplan_and_execute.schema.StepResponse\\nStep response.\\nFunctions¶\\nplan_and_execute.executors.agent_executor.load_agent_executor(...)\\nLoad an agent executor.\\nplan_and_execute.planners.chat_planner.load_chat_planner(llm)\\nLoad a chat planner.\\nlangchain_experimental.prompt_injection_identifier¶\\nHuggingFace Injection Identifier is a tool that uses\\n[HuggingFace Prompt Injection model](https://huggingface.co/deepset/deberta-v3-base-injection)\\nto detect prompt injection attacks.\\nClasses¶\\nprompt_injection_identifier.hugging_face_identifier.HuggingFaceInjectionIdentifier\\nTool that uses HuggingFace Prompt Injection model to detect prompt injection attacks.\\nprompt_injection_identifier.hugging_face_identifier.PromptInjectionException([...])\\nException raised when prompt injection attack is detected.\\nlangchain_experimental.recommenders¶\\nAmazon Personalize primitives.\\n[Amazon Personalize](https://docs.aws.amazon.com/personalize/latest/dg/what-is-personalize.html)\\nis a fully managed machine learning service that uses your data to generate\\nitem recommendations for your users.\\nClasses¶\\nrecommenders.amazon_personalize.AmazonPersonalize([...])\\nAmazon Personalize Runtime wrapper for executing real-time operations.\\nrecommenders.amazon_personalize_chain.AmazonPersonalizeChain\\nChain for retrieving recommendations from Amazon Personalize,\\nlangchain_experimental.retrievers¶\\nRetriever class returns Documents given a text query.\\nIt is more general than a vector store. A retriever does not need to be able to\\nstore documents, only to return (or retrieve) it.\\nClasses¶\\nretrievers.vector_sql_database.VectorSQLDatabaseChainRetriever\\nRetriever that uses Vector SQL Database.\\nlangchain_experimental.rl_chain¶\\nRL (Reinforcement Learning) Chain leverages the Vowpal Wabbit (VW) models\\nfor reinforcement learning with a context, with the goal of modifying\\nthe prompt before the LLM call.\\n[Vowpal Wabbit](https://vowpalwabbit.org/) provides fast, efficient,\\nand flexible online machine learning techniques for reinforcement learning,\\nsupervised learning, and more.\\nClasses¶\\nrl_chain.base.AutoSelectionScorer\\nAuto selection scorer.\\nrl_chain.base.Embedder(*args,\\xa0**kwargs)\\nAbstract class to represent an embedder.\\nrl_chain.base.Event(inputs[,\\xa0selected])\\nAbstract class to represent an event.\\nrl_chain.base.Policy(**kwargs)\\nAbstract class to represent a policy.\\nrl_chain.base.RLChain\\nChain that leverages the Vowpal Wabbit (VW) model as a learned policy for reinforcement learning.\\nrl_chain.base.Selected()\\nAbstract class to represent the selected item.\\nrl_chain.base.SelectionScorer\\nAbstract class to grade the chosen selection or the response of the llm.\\nrl_chain.base.VwPolicy(model_repo,\\xa0vw_cmd,\\xa0...)\\nVowpal Wabbit policy.\\nrl_chain.metrics.MetricsTrackerAverage(step)\\nMetrics Tracker Average.\\nrl_chain.metrics.MetricsTrackerRollingWindow(...)\\nMetrics Tracker Rolling Window.\\nrl_chain.model_repository.ModelRepository(folder)\\nModel Repository.\\nrl_chain.pick_best_chain.PickBest\\nChain that leverages the Vowpal Wabbit (VW) model for reinforcement learning with a context, with the goal of modifying the prompt before the LLM call.\\nrl_chain.pick_best_chain.PickBestEvent(...)\\nEvent class for PickBest chain.\\nrl_chain.pick_best_chain.PickBestFeatureEmbedder(...)\\nEmbed the BasedOn and ToSelectFrom inputs into a format that can be used by the learning policy.\\nrl_chain.pick_best_chain.PickBestRandomPolicy(...)\\nRandom policy for PickBest chain.\\nrl_chain.pick_best_chain.PickBestSelected([...])\\nSelected class for PickBest chain.\\nrl_chain.vw_logger.VwLogger(path)\\nVowpal Wabbit custom logger.\\nFunctions¶\\nrl_chain.base.BasedOn(anything)\\nWrap a value to indicate that it should be based on.\\nrl_chain.base.Embed(anything[,\\xa0keep])\\nWrap a value to indicate that it should be embedded.\\nrl_chain.base.EmbedAndKeep(anything)\\nWrap a value to indicate that it should be embedded and kept.\\nrl_chain.base.ToSelectFrom(anything)\\nWrap a value to indicate that it should be selected from.\\nrl_chain.base.embed(to_embed,\\xa0model[,\\xa0namespace])\\nEmbed the actions or context using the SentenceTransformer model (or a model that has an encode function).\\nrl_chain.base.embed_dict_type(item,\\xa0model)\\nEmbed a dictionary item.\\nrl_chain.base.embed_list_type(item,\\xa0model[,\\xa0...])\\nEmbed a list item.\\nrl_chain.base.embed_string_type(item,\\xa0model)\\nEmbed a string or an _Embed object.\\nrl_chain.base.get_based_on_and_to_select_from(inputs)\\nGet the BasedOn and ToSelectFrom from the inputs.\\nrl_chain.base.is_stringtype_instance(item)\\nCheck if an item is a string.\\nrl_chain.base.parse_lines(parser,\\xa0input_str)\\nParse the input string into a list of examples.\\nrl_chain.base.prepare_inputs_for_autoembed(inputs)\\nPrepare the inputs for auto embedding.\\nrl_chain.base.stringify_embedding(embedding)\\nConvert an embedding to a string.\\nlangchain_experimental.smart_llm¶\\nSmartGPT chain is applying self-critique using the SmartGPT workflow.\\nSee details at https://youtu.be/wVzuvf9D9BU\\nThe workflow performs these 3 steps:\\n1. Ideate: Pass the user prompt to an Ideation LLM n_ideas times,\\neach result is an “idea”\\nCritique: Pass the ideas to a Critique LLM which looks for flaws in the ideas\\n& picks the best one\\nResolve: Pass the critique to a Resolver LLM which improves upon the best idea\\n& outputs only the (improved version of) the best output\\nIn total, the SmartGPT workflow will use n_ideas+2 LLM calls\\nNote that SmartLLMChain will only improve results (compared to a basic LLMChain),\\nwhen the underlying models have the capability for reflection, which smaller models\\noften don’t.\\nFinally, a SmartLLMChain assumes that each underlying LLM outputs exactly 1 result.\\nClasses¶\\nsmart_llm.base.SmartLLMChain\\nChain for applying self-critique using the SmartGPT workflow.\\nlangchain_experimental.sql¶\\nSQL Chain interacts with SQL Database.\\nClasses¶\\nsql.base.SQLDatabaseChain\\nChain for interacting with SQL Database.\\nsql.base.SQLDatabaseSequentialChain\\nChain for querying SQL database that is a sequential chain.\\nsql.vector_sql.VectorSQLDatabaseChain\\nChain for interacting with Vector SQL Database.\\nsql.vector_sql.VectorSQLOutputParser\\nOutput Parser for Vector SQL.\\nsql.vector_sql.VectorSQLRetrieveAllOutputParser\\nParser based on VectorSQLOutputParser.\\nFunctions¶\\nsql.vector_sql.get_result_from_sqldb(db,\\xa0cmd)\\nGet result from SQL Database.\\nlangchain_experimental.tabular_synthetic_data¶\\nGenerate tabular synthetic data using LLM and few-shot template.\\nClasses¶\\ntabular_synthetic_data.base.SyntheticDataGenerator\\nGenerate synthetic data using the given LLM and few-shot template.\\nFunctions¶\\ntabular_synthetic_data.openai.create_openai_data_generator(...)\\nCreate an instance of SyntheticDataGenerator tailored for OpenAI models.\\nlangchain_experimental.text_splitter¶\\nExperimental text splitter based on semantic similarity.\\nClasses¶\\ntext_splitter.SemanticChunker(embeddings[,\\xa0...])\\nSplit the text based on semantic similarity.\\nFunctions¶\\ntext_splitter.calculate_cosine_distances(...)\\nCalculate cosine distances between sentences.\\ntext_splitter.combine_sentences(sentences[,\\xa0...])\\nCombine sentences based on buffer size.\\nlangchain_experimental.tools¶\\nExperimental Python REPL tools.\\nClasses¶\\ntools.python.tool.PythonAstREPLTool\\nTool for running python code in a REPL.\\ntools.python.tool.PythonInputs\\nPython inputs.\\ntools.python.tool.PythonREPLTool\\nTool for running python code in a REPL.\\nFunctions¶\\ntools.python.tool.sanitize_input(query)\\nSanitize input to the python REPL.\\nlangchain_experimental.tot¶\\nImplementation of a Tree of Thought (ToT) chain based on the paper\\n[Large Language Model Guided Tree-of-Thought](https://arxiv.org/pdf/2305.08291.pdf).\\nThe Tree of Thought (ToT) chain uses a tree structure to explore the space of\\npossible solutions to a problem.\\nClasses¶\\ntot.base.ToTChain\\nChain implementing the Tree of Thought (ToT).\\ntot.checker.ToTChecker\\nTree of Thought (ToT) checker.\\ntot.controller.ToTController([c])\\nTree of Thought (ToT) controller.\\ntot.memory.ToTDFSMemory([stack])\\nMemory for the Tree of Thought (ToT) chain.\\ntot.prompts.CheckerOutputParser\\nParse and check the output of the language model.\\ntot.prompts.JSONListOutputParser\\nParse the output of a PROPOSE_PROMPT response.\\ntot.thought.Thought\\nA thought in the ToT.\\ntot.thought.ThoughtValidity(value)\\nEnum for the validity of a thought.\\ntot.thought_generation.BaseThoughtGenerationStrategy\\nBase class for a thought generation strategy.\\ntot.thought_generation.ProposePromptStrategy\\nStrategy that is sequentially using a \"propose prompt\".\\ntot.thought_generation.SampleCoTStrategy\\nSample strategy from a Chain-of-Thought (CoT) prompt.\\nFunctions¶\\ntot.prompts.get_cot_prompt()\\nGet the prompt for the Chain of Thought (CoT) chain.\\ntot.prompts.get_propose_prompt()\\nGet the prompt for the PROPOSE_PROMPT chain.\\nlangchain_experimental.utilities¶\\nUtility that simulates a standalone Python REPL.\\nClasses¶\\nutilities.python.PythonREPL\\nSimulates a standalone Python REPL.\\nlangchain_experimental.video_captioning¶\\nClasses¶\\nvideo_captioning.base.VideoCaptioningChain\\nVideo Captioning Chain.\\nvideo_captioning.models.AudioModel(...)\\nvideo_captioning.models.BaseModel(...)\\nvideo_captioning.models.CaptionModel(...)\\nvideo_captioning.models.VideoModel(...)\\nvideo_captioning.services.audio_service.AudioProcessor(api_key)\\nvideo_captioning.services.caption_service.CaptionProcessor(llm)\\nvideo_captioning.services.combine_service.CombineProcessor(llm)\\nvideo_captioning.services.image_service.ImageProcessor([...])\\nvideo_captioning.services.srt_service.SRTProcessor()')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd976f6-ce96-4b19-a683-d0906ba3e4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0438f6-d8f2-480a-864b-71d44829e0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bf4aa4-f049-46e7-9ad6-1b902dc49110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3b43bf-bccd-4962-b6f2-22e105183332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceb82b9-85c5-4202-a305-83e2518d69ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3161716d-60df-4240-a590-69986c18049a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111998bf-84c6-459d-b13b-db6f0af6a594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
