{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97f44fbc-be5a-477c-9894-b232ea019e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"'/Users/A118390615/Library/CloudStorage/OneDrive-DeutscheTelekomAG/Projects/COE_Projects/langchain_EM_course1/intro_to_vector_dbs/\")\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"OPENAI_API_KEY_PERSONAL\"]\n",
    "\n",
    "from langchain_community.document_loaders.text import TextLoader\n",
    "from langchain_text_splitters.character import CharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain import hub\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain.chains.combine_documents.stuff import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f999bdb3-7187-4f46-beb7-f8b26fe3f56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingestion\n",
      "Ingestion Finish\n",
      "Retrieval paradigm\n"
     ]
    }
   ],
   "source": [
    "loader = TextLoader(r\"data/mediumArticle.txt\")\n",
    "text = loader.load()\n",
    "\n",
    "splitter = CharacterTextSplitter(separator = \"\\n\\n\", \n",
    "                                 chunk_size = 1000, \n",
    "                                 chunk_overlap = 100)\n",
    "text_splits = splitter.split_documents(text)\n",
    "embeddings = OpenAIEmbeddings(model = 'text-embedding-3-small')\n",
    "print(\"Ingestion\")\n",
    "vector_store = PineconeVectorStore(index_name=\"medium-blogs-embedding-index\",\n",
    "                                   embedding = embeddings)\n",
    "vector_store.add_documents(text_splits)\n",
    "print(\"Ingestion Finish\")\n",
    "\n",
    "print(\"Retrieval paradigm\")\n",
    "llm = ChatOpenAI(model = \"gpt-4o-mini\", temperature = 0)\n",
    "rag_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
    "retrieval_qa_chain = create_stuff_documents_chain(llm, rag_prompt)\n",
    "retrieval_chain = create_retrieval_chain(retriever = vector_store.as_retriever(), combine_docs_chain = retrieval_qa_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "838a521f-c764-4bbc-92af-5781b596412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_Result = retrieval_chain.invoke({\"input\": \"How can i use a vector DB\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "27462afe-4907-4d97-8722-1ad92f65a9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use a Vector Database (VectorDB), you can follow these steps:\n",
      "\n",
      "1. **Install the Required Libraries**: You need a library like faiss (Facebook AI Similarity Search) or Annoy (Approximate Nearest Neighbors Oh Yeah). For this example, you can install faiss using the following command:\n",
      "   ```\n",
      "   pip install faiss-cpu\n",
      "   ```\n",
      "\n",
      "2. **Import the Library**: In your Python script, import the necessary libraries:\n",
      "   ```python\n",
      "   import faiss\n",
      "   import numpy as np\n",
      "   ```\n",
      "\n",
      "3. **Create Some Vector Data**: Generate sample vectors that you want to store in the VectorDB. For example:\n",
      "   ```python\n",
      "   d = 128  # Dimension of vectors\n",
      "   nb = 1000  # Number of vectors\n",
      "   np.random.seed(1234)\n",
      "   vectors = np.random.random((nb, d)).astype('float32')\n",
      "   ```\n",
      "\n",
      "4. **Build the Index**: Create an index to store the vectors and make similarity searches efficient:\n",
      "   ```python\n",
      "   index = faiss.IndexFlatL2(d)  # L2 distance\n",
      "   index.add(vectors)  # Add vectors to the index\n",
      "   print(f\"Number of vectors in the index: {index.ntotal}\")\n",
      "   ```\n",
      "\n",
      "5. **Perform a Similarity Search**: You can now search for the top similar vectors to a query vector. For example, if you have a query vector, you can find the top 5 similar vectors:\n",
      "   ```python\n",
      "   # Example query vector\n",
      "   query_vector = np.random.random((1, d)).astype('float32')\n",
      "   k = 5  # Number of nearest neighbors to search\n",
      "   distances, indices = index.search(query_vector, k)\n",
      "   print(\"Distances:\", distances)\n",
      "   print(\"Indices of nearest neighbors:\", indices)\n",
      "   ```\n",
      "\n",
      "By following these steps, you can effectively use a VectorDB for storing and retrieving vector data.\n"
     ]
    }
   ],
   "source": [
    "print(sample_Result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4aca08fa-a0a5-45e7-bfe2-e7b79e61f981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e67e8af-c27c-4f11-87ad-29bf9bec53bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='Answer any use questions based solely on the context below:\\n\\n<context>\\n{context}\\n</context>'), additional_kwargs={})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_prompt.messages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95a4ca34-26a9-4df5-a6c1-89020db6a02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatPromptTemplate(input_variables=['context', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x1072b3880>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'langchain-ai', 'lc_hub_repo': 'retrieval-qa-chat', 'lc_hub_commit_hash': 'b60afb6297176b022244feb83066e10ecadcda7b90423654c4a9d45e7a73cebc'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='Answer any use questions based solely on the context below:\\n\\n<context>\\n{context}\\n</context>'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f066ea-8c13-4467-8a31-cf26a479c4d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25295d0-b11d-4d83-80cf-3cc5a05d56bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e244dc-c5c0-4cd0-ae6b-044f06e23fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eca318c1-5534-465a-8a22-ecabb442f0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='28a6479e-c706-401a-8fea-847448e89bc3', metadata={'source': 'data/mediumArticle.txt'}, page_content='Example Technologies and Tools\\n\\n    FAISS (Facebook AI Similarity Search):\\n\\n    A library for efficient similarity search and clustering of dense vectors.\\n    Supports a range of indexing algorithms and is optimized for both CPU and GPU.\\n\\n    Annoy (Approximate Nearest Neighbors Oh Yeah):\\n\\n    A library for approximate nearest neighbor search, particularly useful for large, read-only datasets.\\n    Uses a combination of random projections and trees for indexing.\\n\\n    HNSW (Hierarchical Navigable Small World):\\n\\n    An algorithm for efficient approximate nearest neighbor search.\\n    Utilizes a graph-based structure for fast and scalable search.\\n\\n    Milvus:\\n\\n    An open-source vector database designed for scalable similarity search.\\n    Supports hybrid search combining vector and traditional databases.\\n\\nSteps to Use VectorDB\\n1. Install the Required Libraries'),\n",
       " Document(id='f72f3000-5725-47b2-b118-ffa7a18e56a9', metadata={'source': 'data/mediumArticle.txt'}, page_content='Dimensionality Reduction:\\n\\n    Techniques like Principal Component Analysis (PCA) and t-SNE are used to reduce the number of dimensions in vectors while preserving their significant properties.\\n    This helps in speeding up the search and reducing storage requirements.\\n\\nVectorDB Architecture\\n\\n    Data Ingestion Layer:\\n\\n    Handles the input of raw data and processes it into vector representations using feature extraction models like neural networks.\\n    Ensures data is normalized and transformed appropriately before indexing.\\n\\n    Indexing Layer:\\n\\n    Responsible for creating and maintaining the index of vectors.\\n    Employs various indexing algorithms to balance between accuracy and performance.\\n\\n    Storage Layer:\\n\\n    Stores the vectors and the indices.\\n    Can be designed for both in-memory storage for fast access and disk-based storage for handling large datasets.\\n\\n    Query Processing Layer:'),\n",
       " Document(id='03fdddb0-62d4-4b90-9d46-e8e2abc0afbf', metadata={'source': 'data/mediumArticle.txt'}, page_content='Query Processing Layer:\\n\\n    Manages the execution of similarity search queries.\\n    Utilizes the index to quickly retrieve the nearest neighbors to the query vector.\\n    Often includes components for filtering, ranking, and aggregating search results.\\n\\n    API Layer:\\n\\n    Provides interfaces for interacting with the VectorDB.\\n    Includes functionalities for adding, updating, deleting vectors, and executing search queries.\\n\\nUse Cases of VectorDB\\n\\n    Recommendation Systems:\\n\\n    Powering personalized recommendations by finding similar users or items based on their vector representations.\\n    Examples: Movie, music, or product recommendations.\\n\\n    Image and Video Retrieval:\\n\\n    Enabling content-based image and video retrieval by searching for similar visual features.\\n    Examples: Google Images, Pinterest visual search.\\n\\n    Natural Language Processing (NLP):'),\n",
       " Document(id='9e49bd27-aec4-4b14-9543-3c4dc3a4effa', metadata={'source': 'data/mediumArticle.txt'}, page_content='Natural Language Processing (NLP):\\n\\n    Finding semantically similar texts, documents, or queries using vector embeddings from models like BERT or Word2Vec.\\n    Examples: Document clustering, sentiment analysis, semantic search.\\n\\n    Anomaly Detection:\\n\\n    Identifying unusual patterns or outliers in high-dimensional data.\\n    Examples: Fraud detection, network intrusion detection.\\n\\n    Biometric Identification:\\n\\n    Matching biometric data such as fingerprints, facial recognition, or iris scans by comparing vectorized features.\\n    Examples: Security systems, user authentication.\\n\\n    Genomics and Bioinformatics:\\n\\n    Analyzing genetic sequences and biological data by comparing vector representations of DNA, RNA, or protein sequences.\\n    Examples: Disease research, personalized medicine.\\n\\nExample Technologies and Tools\\n\\n    FAISS (Facebook AI Similarity Search):')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.similarity_search(query = \"best options to Pinecone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f78913-6fff-4a5e-965d-29116b6be2ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c494ce0-9754-4605-91b8-2181b840cb8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f958c5d-a044-4687-9d31-e0b18a3edf68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f191334f-d05a-40c2-b30f-551c716d9ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
